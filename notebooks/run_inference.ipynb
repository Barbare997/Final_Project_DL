{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Webcam Demo\n",
        "\n",
        "Real-time emotion recognition from webcam feed."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Install packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# !pip install opencv-python torch torchvision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "sys.path.append('../src')\n",
        "sys.path.append('src')\n",
        "\n",
        "from model import EmotionCNN\n",
        "from config import EMOTION_CLASSES, IMG_SIZE, DEVICE\n",
        "from utils import preprocess_image_for_inference\n",
        "\n",
        "device = torch.device(DEVICE)\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model_path = \"models/cnn_model.pth\"\n",
        "\n",
        "if not os.path.exists(model_path):\n",
        "    print(f\"Model not found at {model_path}\")\n",
        "    print(\"Train the model first using run_training.ipynb\")\n",
        "else:\n",
        "    model = EmotionCNN(num_classes=7)\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(\"Model loaded\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run webcam demo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
        "\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "if not cap.isOpened():\n",
        "    print(\"Could not open webcam\")\n",
        "else:\n",
        "    print(\"Press 'q' to quit\")\n",
        "    \n",
        "    while True:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        \n",
        "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "        faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
        "        \n",
        "        if len(faces) > 0:\n",
        "            x, y, w, h = faces[0]\n",
        "            \n",
        "            face_roi = gray[y:y+h, x:x+w]\n",
        "            face_resized = cv2.resize(face_roi, (IMG_SIZE, IMG_SIZE))\n",
        "            \n",
        "            tensor = preprocess_image_for_inference(face_resized).to(device)\n",
        "            \n",
        "            with torch.no_grad():\n",
        "                outputs = model(tensor)\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "                confidence = probs[0][predicted].item()\n",
        "            \n",
        "            emotion = EMOTION_CLASSES[predicted.item()]\n",
        "            \n",
        "            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "            label = f\"{emotion} ({confidence:.2f})\"\n",
        "            cv2.putText(frame, label, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)\n",
        "        \n",
        "        cv2.imshow('Emotion Recognition', frame)\n",
        "        \n",
        "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "            break\n",
        "    \n",
        "    cap.release()\n",
        "    cv2.destroyAllWindows()\n",
        "    print(\"Done\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
